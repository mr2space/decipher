{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.16.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4076 images belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(r'dataset\\training',\n",
    "                                                 target_size = (128,128),\n",
    "                                                 batch_size = 5,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2824 images belonging to 80 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory(r'dataset\\test',\n",
    "                                            target_size = (128,128),\n",
    "                                            batch_size = 400,\n",
    "                                            class_mode = 'categorical'\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating cnn sequential\n",
    "cnn = tf.keras.models.Sequential()\n",
    "\n",
    "\n",
    "#adding filter, pooler and Flater\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size = 3, activation='relu', input_shape=[128, 128, 3]))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#adding deep neural network to cnn\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dense(units=80, activation='softmax'))\n",
    "\n",
    "cnn.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 322ms/step - accuracy: 0.0357 - loss: 4.3052 - val_accuracy: 0.0322 - val_loss: 4.5114\n",
      "Epoch 2/50\n",
      "\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 284ms/step - accuracy: 0.0988 - loss: 3.8616 - val_accuracy: 0.0648 - val_loss: 4.7369\n",
      "Epoch 3/50\n",
      "\u001b[1m816/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 269ms/step - accuracy: 0.1759 - loss: 3.3724 - val_accuracy: 0.0974 - val_loss: 4.4623\n",
      "Epoch 4/50\n",
      "\u001b[1m681/816\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.2448 - loss: 3.0261"
     ]
    }
   ],
   "source": [
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"cnn_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img(r'C:\\Users\\rahul\\Downloads\\WhatsApp Image 2024-07-05 at 3.58.50 PM.jpeg', target_size = (128, 128))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Aloevera': 0, 'Amla': 1, 'Amruthaballi': 2, 'Arali': 3, 'Astma_weed': 4, 'Badipala': 5, 'Balloon_Vine': 6, 'Bamboo': 7, 'Beans': 8, 'Betel': 9, 'Bhrami': 10, 'Bringaraja': 11, 'Caricature': 12, 'Castor': 13, 'Catharanthus': 14, 'Chakte': 15, 'Chilly': 16, 'Citron lime (herelikai)': 17, 'Coffee': 18, 'Common rue(naagdalli)': 19, 'Coriender': 20, 'Curry': 21, 'Doddpathre': 22, 'Drumstick': 23, 'Ekka': 24, 'Eucalyptus': 25, 'Ganigale': 26, 'Ganike': 27, 'Gasagase': 28, 'Ginger': 29, 'Globe Amarnath': 30, 'Guava': 31, 'Henna': 32, 'Hibiscus': 33, 'Honge': 34, 'Insulin': 35, 'Jackfruit': 36, 'Jasmine': 37, 'Kambajala': 38, 'Kasambruga': 39, 'Kohlrabi': 40, 'Lantana': 41, 'Lemon': 42, 'Lemongrass': 43, 'Malabar_Nut': 44, 'Malabar_Spinach': 45, 'Mango': 46, 'Marigold': 47, 'Mint': 48, 'Neem': 49, 'Nelavembu': 50, 'Nerale': 51, 'Nooni': 52, 'Onion': 53, 'Padri': 54, 'Palak(Spinach)': 55, 'Papaya': 56, 'Parijatha': 57, 'Pea': 58, 'Pepper': 59, 'Pomoegranate': 60, 'Pumpkin': 61, 'Raddish': 62, 'Rose': 63, 'Sampige': 64, 'Sapota': 65, 'Seethaashoka': 66, 'Seethapala': 67, 'Spinach1': 68, 'Tamarind': 69, 'Taro': 70, 'Tecoma': 71, 'Thumbe': 72, 'Tomato': 73, 'Tulsi': 74, 'Turmeric': 75, 'ashoka': 76, 'camphor': 77, 'kamakasturi': 78, 'kepala': 79}\n",
      "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "training_set.class_indices\n",
    "print(training_set.class_indices)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"trainingSet_class.pkl\", \"wb\") as file:\n",
    "    pickle.dump(training_set.class_indices, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
